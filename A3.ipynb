{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523f1295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# Abdelazim Lokma\n",
    "# Risheet Nair\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import cv2 as cv\n",
    "# import cv2_imshow\n",
    "\n",
    "# part 1:\n",
    "\n",
    "def load_obj_each_frame(data_file):\n",
    "  with open(data_file, 'r') as file:\n",
    "    frame_dict = json.load(file)\n",
    "  return frame_dict\n",
    "def draw_target_object_center(video_file,obj_centers):\n",
    "  count = 0\n",
    "  cap = cv.VideoCapture(video_file)\n",
    "  frames = []\n",
    "  ok, image = cap.read()\n",
    "  vidwrite = cv.VideoWriter(\"part_1_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "  while ok:\n",
    "    pos_x,pos_y = obj_centers[count]\n",
    "    count+=1\n",
    "    ######!!!!#######\n",
    "    image = cv.resize(image, (700, 500)) # make sure your video is resize to this size, otherwise the coords in the data file won't work !!!\n",
    "    ######!!!!#######\n",
    "    image = cv.circle(image, (int(pos_x),int(pos_y)), 1, (0,0,255), 2)\n",
    "    vidwrite.write(image)\n",
    "    ok, image = cap.read()\n",
    "  vidwrite.release()\n",
    "\n",
    "\n",
    "frame_dict = load_obj_each_frame(\"object_to_track.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_target_object_center(video_file,frame_dict['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b52ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b74d6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'part_1_object_tracking.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    object_pos = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "973e5546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, P, A, Q):\n",
    "    # Make sure that x is a 1D array with shape (2,)\n",
    "    x = np.array(x).flatten()\n",
    "\n",
    "    # Predict the next state\n",
    "    x_pred = A.dot(x)\n",
    "\n",
    "    # Predict the next covariance matrix\n",
    "    P_pred = A.dot(P).dot(A.T) + Q\n",
    "\n",
    "    return x_pred, P_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abaaa672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(x_pred, P_pred, z, H, R):\n",
    "    # Ensure x_pred is a 2-element 1D array\n",
    "    x_pred = np.array(x_pred).flatten()\n",
    "\n",
    "    # Innovation or residual, should be a 2-element 1D array\n",
    "    y = z - H.dot(x_pred)\n",
    "    # System uncertainty, should be a 2x2 matrix\n",
    "    S = H.dot(P_pred).dot(H.T) + R\n",
    "    # Kalman gain, should be a 2x2 matrix\n",
    "    K = P_pred.dot(H.T).dot(np.linalg.inv(S))\n",
    "    # Updated state estimate, should be a 2-element 1D array\n",
    "    x_update = x_pred + K.dot(y)\n",
    "    I = np.eye(P_pred.shape[0])  # Identity matrix\n",
    "    # Updated estimate uncertainty, should be a 2x2 matrix\n",
    "    P_update = (I - K.dot(H)).dot(P_pred)\n",
    "\n",
    "    return x_update, P_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4fba50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positions(obj_centers, num_passes):\n",
    "    P = np.eye(2)\n",
    "    A = np.array([[0.9981, 0], [0, 0.9972]])\n",
    "    x = [312, 228]\n",
    "    H = np.eye(2)\n",
    "    Q = np.eye(2) * 0.01\n",
    "    R = np.eye(2) * 1\n",
    "    \n",
    "    \n",
    "    positions = {}\n",
    "    positions[\"obj\"] = []\n",
    "\n",
    "    frames = []\n",
    "    frames.append(obj_centers[0])\n",
    "\n",
    "    forward = True\n",
    "    for i in range(num_passes):\n",
    "        count = 0\n",
    "        if (not forward):\n",
    "            x = frames[0]        \n",
    "            A = np.eye(2) * 1.0028\n",
    "            forward = True\n",
    "        else:\n",
    "            if (i != 0):\n",
    "                x = frames[0]\n",
    "            forward= False\n",
    "            A = np.array([[0.9981, 0], [0, 0.9972]])\n",
    "            \n",
    "        while count < len(obj_centers):\n",
    "            if(count == 0 and i== 0):\n",
    "                count += 1\n",
    "                continue\n",
    "            else:\n",
    "                if(i == 0):\n",
    "                    pos_x, pos_y = obj_centers[count]\n",
    "                else:\n",
    "                    pos_x, pos_y = frames[count]\n",
    "                if pos_x != -1 and pos_y != -1:\n",
    "                    z = np.array([pos_x, pos_y])\n",
    "                    x_pred, P_pred = predict(x, P, A, Q)  # predict next frame\n",
    "                    x_update, P_update = update(x_pred, P_pred, z, H, R)\n",
    "                    x_update = x_update.tolist()\n",
    "                    if i==0:\n",
    "                        frames.append([pos_x, pos_y])\n",
    "                    else:\n",
    "                        frames[count] = [pos_x, pos_y]\n",
    "                    x, P = x_update, P_update\n",
    "                else:\n",
    "                    x, P = predict(x, P, A, Q)\n",
    "                    x = x.tolist()  # check the rounding issue\n",
    "                    if i == 0:\n",
    "                        frames.append([x[0], x[1]])\n",
    "                    else:\n",
    "                        frames[count] = [x[0], x[1]]\n",
    "                    \n",
    "            count += 1\n",
    "               \n",
    "        if (not forward):\n",
    "            frames = frames[::-1]\n",
    "            \n",
    "    return frames[::-1]\n",
    "            \n",
    "                \n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13473324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_target_object_center(video_file, obj_centers, forward_pass = True):\n",
    "    P = np.eye(2) \n",
    "    if(forward_pass):\n",
    "        A = np.eye(2) * 0.9972\n",
    "        x = [312, 228]\n",
    "    else:\n",
    "        A = np.eye(2) * 1.0028\n",
    "        x = [155.48221359647187, 95.25131111414534]\n",
    "    H = np.eye(2)\n",
    "    Q = np.eye(2) * 0.01\n",
    "    R = np.eye(2) * 1\n",
    "    count = 0\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    \n",
    "    \n",
    "    positions = {}\n",
    "    positions[\"obj\"] = []\n",
    "    \n",
    "    frames = []  \n",
    "    ok, image = cap.read()\n",
    "    vidwrite = cv.VideoWriter(\"part_1_demo_with_kalman.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "    \n",
    "    \n",
    "    while ok:\n",
    "        if(count == 0 and forward_pass):\n",
    "            count += 1\n",
    "            continue\n",
    "        elif count == 249 and forward_pass:\n",
    "            break\n",
    "        # print(count)\n",
    "        pos_x, pos_y = obj_centers[count]\n",
    "        count += 1\n",
    "        if pos_x != -1 and pos_y != -1:\n",
    "            z = np.array([pos_x, pos_y])\n",
    "            if count == 1:\n",
    "                x = np.array([pos_x, pos_y])\n",
    "                P = np.diag([1, 1])\n",
    "            else:\n",
    "\n",
    "                x_pred, P_pred = predict(x, P, A, Q) #predict next frame \n",
    "\n",
    "                x_update, P_update = update(x_pred, P_pred, z, H, R) #\n",
    "                \n",
    "                x_update = x_update.tolist()\n",
    "                \n",
    "                frames.append([pos_x, pos_y])\n",
    "                positions[\"obj\"] += [[pos_x, pos_y]]\n",
    "                # print(x_update)\n",
    "                image = cv.resize(image, (700, 500))\n",
    "                # print(x_update[0], x_update[1])\n",
    "                # if len(frames) > 1:\n",
    "                #     cv.polylines(image, [np.array(frames)], False, (0, 0, 255), thickness=1)\n",
    "\n",
    "                x, P = x_update, P_update\n",
    "        else:\n",
    "            # print(x)\n",
    "            x, P = predict(x, P, A, Q)\n",
    "            x = x.tolist() #check the rounding issue\n",
    "            frames.append([x[0], x[1]])\n",
    "            positions[\"obj\"] += [[x[0], x[1]]]\n",
    "\n",
    "            # cv.polylines(image, [np.array(frames)], False, (0, 0, 255), thickness=1)\n",
    "        image = cv.resize(image, (700, 500))\n",
    "        # image = cv.circle(image, (pos_x, pos_y), 1, (0, 0, 255), 2)\n",
    "\n",
    "        vidwrite.write(image)\n",
    "        ok, image = cap.read()\n",
    "    vidwrite.release()\n",
    "    if(forward_pass):\n",
    "       filename = 'filled_positions.json'\n",
    "    else:\n",
    "        filename = 'backwards_filled_positions.json'\n",
    "        frames = frames[::-1]\n",
    "        positions[\"obj\"] = positions[\"obj\"][::-1]\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(positions, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50fb5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'part_1_object_tracking.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    object_pos = json.load(file)\n",
    "\n",
    "# draw_target_object_center(video_file, object_pos['obj'])\n",
    "frames = generate_positions(object_pos['obj'], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09d28e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = \"commonwealth.mp4\"\n",
    "# draw_target_object_center(video_file, object_pos['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eca5487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_path(video_file, obj_centers):\n",
    "    obj_centers = [[int(round(x[0])), int(round(x[1]))] for x in obj_centers]\n",
    "    count = 0\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    ok, image = cap.read()\n",
    "    vidwrite = cv.VideoWriter(\n",
    "        \"part_1_demo_with_kalman.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700, 500))\n",
    "\n",
    "    while ok:\n",
    "        if(count == 0):\n",
    "            count += 1\n",
    "            continue\n",
    "        elif count == 248:\n",
    "            break\n",
    "        # print(count)\n",
    "        pos_x, pos_y = obj_centers[count]\n",
    "        count += 1\n",
    "        image = cv.resize(image, (700, 500))\n",
    "        # print([np.array(obj_centers[:count+1])])\n",
    "        cv.polylines(image, [np.array(obj_centers[:count+1])],\n",
    "                     False, (0, 0, 255), thickness=2)\n",
    "        image = cv.circle(image, (pos_x, pos_y), 1, (0, 0, 255), 2)        \n",
    "        vidwrite.write(image)\n",
    "        ok, image = cap.read()\n",
    "    vidwrite.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ceaa61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "create_video_path(video_file, frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9db6b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# part 2:\n",
    "\n",
    "def draw_object(object_dict,image,color = (0, 255, 0), thickness = 2,c_color= \\\n",
    "                (255, 0, 0)):\n",
    "  # draw box\n",
    "  x = object_dict['x_min']\n",
    "  y = object_dict['y_min']\n",
    "  width = object_dict['width']\n",
    "  height = object_dict['height']\n",
    "  image = cv.rectangle(image, (x, y), (x + width, y + height), color, thickness)\n",
    "  return image\n",
    "\n",
    "def draw_objects_in_video(video_file,frame_dict):\n",
    "  count = 0\n",
    "  cap = cv.VideoCapture(video_file)\n",
    "  frames = []\n",
    "  ok, image = cap.read()\n",
    "  vidwrite = cv.VideoWriter(\"part_2_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "  while ok:\n",
    "    ######!!!!#######\n",
    "    image = cv.resize(image, (700, 500)) # make sure your video is resize to this size, otherwise the coords in the data file won't work !!!\n",
    "    ######!!!!#######\n",
    "    obj_list = frame_dict[str(count)]\n",
    "    for obj in obj_list:\n",
    "      image = draw_object(obj,image)\n",
    "    vidwrite.write(image)\n",
    "    count+=1\n",
    "    ok, image = cap.read()\n",
    "  vidwrite.release()\n",
    "\n",
    "frame_dict = load_obj_each_frame(\"frame_dict.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_objects_in_video(video_file,frame_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cc378a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiObjKalmanFilter:\n",
    "    def __init__(self, ):\n",
    "        self.towards_A_matrix = np.eye(2) * 1.0028\n",
    "        self.away_A_matrix = np.eye(2) * 0.9972\n",
    "        self.stationary_A_matrix = np.eye(2)\n",
    "        self.H = np.eye(2)\n",
    "        self.Q = np.eye(2) * 0.01\n",
    "        self.R = np.eye(2) * 1\n",
    "        self.A = self.stationary_A_matrix  # Default A matrix\n",
    "        self.x = np.zeros(2)  # Initial state estimate\n",
    "        self.P = np.eye(2)  # Initial covariance estimate\n",
    "        self.x_last = self.x\n",
    "\n",
    "    def set_motion_status(self):\n",
    "        result = np.floor(self.x) - self.x_last\n",
    "        if np.all(abs(result) <= 1):\n",
    "            self.A = self.stationary_A_matrix\n",
    "        elif np.any(result < 0):\n",
    "           self.A = self.away_A_matrix\n",
    "        elif np.any(result > 0):\n",
    "            self.A = self.towards_A_matrix\n",
    "        else:\n",
    "            raise ValueError(\"Invalid motion status\")\n",
    "\n",
    "    def update(self, z):\n",
    "        self.x_last = z\n",
    "        y = z - self.H.dot(self.x)\n",
    "        S = self.H.dot(self.P).dot(self.H.T) + self.R\n",
    "        K = self.P.dot(self.H.T).dot(np.linalg.inv(S))\n",
    "        self.x = self.x + K.dot(y)\n",
    "        I = np.eye(self.P.shape[0])\n",
    "        self.P = (I - K.dot(self.H)).dot(self.P)\n",
    "        return self.x, self.P\n",
    "\n",
    "    def predict(self):\n",
    "        self.x = self.A.dot(self.x)\n",
    "        self.P = self.A.dot(self.P).dot(self.A.T) + self.Q\n",
    "        return self.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "889a95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update average width/height of a detected object\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def are_coordinates_close(coord1, coord2, margin):\n",
    "   \n",
    "    distance = np.linalg.norm(np.array(coord1) - np.array(coord2))\n",
    "\n",
    "    return distance <= margin\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47c27df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import cv2 as cv\n",
    "# initialization step - give every object a unique ID \n",
    "file_path = 'part_2_frame_dict.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    obj_positions = json.load(file)\n",
    "\n",
    "\n",
    "#set the default ID to -1\n",
    "for frame in obj_positions.values():\n",
    "    for obj in frame:\n",
    "        obj['id'] = -1\n",
    "\n",
    "#keeps track of the size of previously ID'd objects, used to compare with the size of unkown objects to help\n",
    "#with identification\n",
    "# detected_obj_avg_size = {}\n",
    "\n",
    "\n",
    "#known objects\n",
    "prev_positions = obj_positions[\"0\"]\n",
    "\n",
    "#measurements\n",
    "curr_positions = obj_positions[\"1\"]\n",
    "\n",
    "#ID Numtracker:\n",
    "newest_id = 0\n",
    "\n",
    "pixel_threshold = 12\n",
    "\n",
    "\n",
    "for i in range(len(prev_positions)):\n",
    "    prev_positions[i]['id'] = i+1\n",
    "    newest_id += 1;\n",
    "\n",
    "detected_obj_tracks = {}\n",
    "detected_obj_kalmans = {}\n",
    "\n",
    "\n",
    "#initialize kalman filters for all existing objects\n",
    "for object in prev_positions:\n",
    "    detected_obj_kalmans[object['id']] = MultiObjKalmanFilter()\n",
    "    detected_obj_kalmans[object['id']].x = np.array((object[\"x_min\"], object[\"y_min\"]))\n",
    "    detected_obj_tracks[object['id']] = object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f9f146a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obj_detections_test.json'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for frame in list(obj_positions.keys())[1:]:\n",
    "    predicted_kalmans = []\n",
    "    curr_positions = obj_positions[frame]\n",
    "    \n",
    "    #loop handling old objects: assigning to new detections, or ruling them out as having left the frame\n",
    "    for object in prev_positions:\n",
    "        matched = False\n",
    "        obj_estimates = [] #array containing the 3 possible estimated locations of the obj\n",
    "        \n",
    "        #make an estimation assuming no motion\n",
    "        detected_obj_kalmans[object['id']].set_motion_status()\n",
    "        towards_estimation = detected_obj_kalmans[object['id']].predict()\n",
    "        predicted_kalmans.append(object['id'])\n",
    "        obj_estimates.append(towards_estimation)\n",
    "    \n",
    "        \n",
    "        for new_det in curr_positions: #for every newly detected obj\n",
    "            if matched:\n",
    "                break\n",
    "            for i in range(len(obj_estimates)): #for all 3 estimations\n",
    "                # check if model finds a match\n",
    "                if are_coordinates_close(obj_estimates[i].tolist(), [new_det[\"x_min\"], new_det[\"y_min\"]], pixel_threshold):\n",
    "            \n",
    "                    \n",
    "                    new_det['id'] = object['id'] #link the new detection to an existing object\n",
    "                    \n",
    "                    #update the kalman filter instance's estimation with the new measurment, now confirmed to be for that object\n",
    "                    detected_obj_kalmans[object['id']].update(\n",
    "                        np.array([new_det[\"x_min\"], new_det[\"y_min\"]]))\n",
    "                    \n",
    "                    # if match, that object now has a set model for the future\n",
    "                    detected_obj_kalmans[object['id']\n",
    "                                         ].set_motion_status()\n",
    "                    matched = True\n",
    "                else:\n",
    "                    continue \n",
    "            \n",
    "            \n",
    "            \n",
    "    #loop handling new objects that have not found a match from previous frame (could either be new objects or objects that already exist but were\n",
    "    # not in the previous frame for whatever reason)\n",
    "    for new_detection in curr_positions:\n",
    "        if new_detection['id'] == -1:\n",
    "            matched = False\n",
    "            for old_obj in detected_obj_tracks.values():\n",
    "                if are_coordinates_close(np.array([new_detection[\"x_min\"], new_detection[\"y_min\"]]), np.array([old_obj[\"x_min\"], old_obj[\"y_min\"]]), pixel_threshold):\n",
    "                    #the \"new\" object was actually an old object that we lost track of in the last frame\n",
    "                    new_detection['id'] = old_obj['id'] #update it's ID and kalman filters accordingly \n",
    "                    detected_obj_kalmans[object['id']].update(\n",
    "                        np.array([new_detection[\"x_min\"], new_detection[\"y_min\"]]))\n",
    "                    matched = True\n",
    "            \n",
    "            if (not matched): #the new object was not detected in the last frame or any previous frames, create a new object ID for it \n",
    "                newest_id += 1  # create a new ID for the new obj and assign\n",
    "                new_detection['id'] = newest_id\n",
    "                #create its kalman filter instance and initialize it\n",
    "                detected_obj_kalmans[new_detection['id']] = MultiObjKalmanFilter()\n",
    "                detected_obj_kalmans[new_detection['id']].x = np.array(\n",
    "                    [new_detection[\"x_min\"], new_detection[\"y_min\"]])\n",
    "\n",
    "\n",
    "    for new_detection in curr_positions:\n",
    "    #update the object database withe the new coordinates of all currently tracked objects\n",
    "        detected_obj_tracks[new_detection['id']\n",
    "                            ] = new_detection\n",
    "    \n",
    "    \n",
    "    #predict for all filters that did not yet do so (incase we lost track of an object that will re-appear later)\n",
    "    for object_id, kalman_filter in detected_obj_kalmans.items():\n",
    "        if object_id not in predicted_kalmans:\n",
    "            kalman_filter.predict()\n",
    "        \n",
    "        \n",
    "    #the curr_positions dictionairy now contains identified objects\n",
    "    obj_positions[frame] = curr_positions\n",
    "    prev_positions = curr_positions\n",
    "    \n",
    "\n",
    "file_path = \"obj_detections_test.json\"\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(obj_positions, json_file)\n",
    "\n",
    "file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9565f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import json\n",
    "\n",
    "\n",
    "def load_obj_each_frame(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def draw_object(object_dict, image, color=(0, 255, 0), thickness=2, c_color=(255, 0, 0)):\n",
    "  # draw box\n",
    "  x = object_dict['x_min']\n",
    "  y = object_dict['y_min']\n",
    "  width = object_dict['width']\n",
    "  height = object_dict['height']\n",
    "  id = object_dict['id']\n",
    "  image = cv.rectangle(\n",
    "      image, (x, y), (x + width, y + height), color, thickness)\n",
    "  cv.putText(image, str(id), (x, y - 10),\n",
    "             cv.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "  return image\n",
    "\n",
    "def draw_objects_in_video(video_file, frame_dict):\n",
    "  count = 0\n",
    "  cap = cv.VideoCapture(video_file)\n",
    "  frames = []\n",
    "  ok, image = cap.read()\n",
    "  vidwrite = cv.VideoWriter(\n",
    "      \"part_2_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700, 500))\n",
    "  while ok:\n",
    "    ######!!!!#######\n",
    "    # make sure your video is resize to this size, otherwise the coords in the data file won't work !!!\n",
    "    image = cv.resize(image, (700, 500))\n",
    "    ######!!!!#######\n",
    "    obj_list = frame_dict[str(count)]\n",
    "    for obj in obj_list:\n",
    "      image = draw_object(obj, image)\n",
    "    vidwrite.write(image)\n",
    "    count += 1\n",
    "    ok, image = cap.read()\n",
    "  vidwrite.release()\n",
    "\n",
    "\n",
    "# Assuming the JSON file is named \"frame_dict.json\" and the video file is named \"commonwealth.mp4\"\n",
    "frame_dict = load_obj_each_frame(\"obj_detections_test.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_objects_in_video(video_file, frame_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
