{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "523f1295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import cv2 as cv\n",
    "# import cv2_imshow\n",
    "\n",
    "# part 1:\n",
    "\n",
    "def load_obj_each_frame(data_file):\n",
    "  with open(data_file, 'r') as file:\n",
    "    frame_dict = json.load(file)\n",
    "  return frame_dict\n",
    "def draw_target_object_center(video_file,obj_centers):\n",
    "  count = 0\n",
    "  cap = cv.VideoCapture(video_file)\n",
    "  frames = []\n",
    "  ok, image = cap.read()\n",
    "  vidwrite = cv.VideoWriter(\"part_1_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "  while ok:\n",
    "    pos_x,pos_y = obj_centers[count]\n",
    "    count+=1\n",
    "    ######!!!!#######\n",
    "    image = cv.resize(image, (700, 500)) # make sure your video is resize to this size, otherwise the coords in the data file won't work !!!\n",
    "    ######!!!!#######\n",
    "    image = cv.circle(image, (int(pos_x),int(pos_y)), 1, (0,0,255), 2)\n",
    "    vidwrite.write(image)\n",
    "    ok, image = cap.read()\n",
    "  vidwrite.release()\n",
    "\n",
    "\n",
    "frame_dict = load_obj_each_frame(\"object_to_track.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_target_object_center(video_file,frame_dict['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1b52ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b74d6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'part_1_object_tracking.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    object_pos = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9f1ff52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'obj': [[-1, -1], [312, 228], [311, 228], [318, 205], [-1, -1], [-1, -1], [307, 225], [306, 224], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [287, 207], [287, 206], [286, 205], [286, 203], [-1, -1], [285, 202], [284, 202], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [278, 198], [276, 197], [-1, -1], [-1, -1], [275, 196], [-1, -1], [272, 194], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [262, 186], [261, 186], [260, 184], [260, 185], [259, 184], [258, 184], [257, 183], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [252, 176], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [232, 156], [232, 156], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [225, 148], [-1, -1], [-1, -1], [224, 148], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [219, 141], [218, 141], [217, 141], [216, 139], [216, 139], [216, 139], [216, 139], [216, 138], [-1, -1], [213, 138], [212, 137], [213, 136], [211, 136], [212, 135], [211, 135], [210, 132], [211, 132], [-1, -1], [209, 132], [207, 132], [207, 131], [205, 131], [206, 131], [205, 130], [204, 130], [203, 130], [203, 130], [203, 129], [203, 128], [202, 128], [-1, -1], [199, 128], [199, 127], [198, 127], [198, 127], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [193, 121], [193, 122], [193, 120], [193, 120], [192, 120], [-1, -1], [190, 120], [191, 120], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [177, 109], [178, 108], [177, 108], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [171, 108], [-1, -1], [171, 107], [-1, -1], [-1, -1], [170, 107], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [169, 102], [168, 103], [168, 103], [167, 102], [167, 102], [167, 101], [167, 101], [166, 100], [166, 101], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1]]}\n"
     ]
    }
   ],
   "source": [
    "print(object_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eda836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "973e5546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, P, A, Q):\n",
    "    # Make sure that x is a 1D array with shape (2,)\n",
    "    x = np.array(x).flatten()\n",
    "\n",
    "    # Predict the next state\n",
    "    x_pred = A.dot(x)\n",
    "\n",
    "    # Predict the next covariance matrix\n",
    "    P_pred = A.dot(P).dot(A.T) + Q\n",
    "\n",
    "    return x_pred, P_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "abaaa672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(x_pred, P_pred, z, H, R):\n",
    "    # Ensure x_pred is a 2-element 1D array\n",
    "    x_pred = np.array(x_pred).flatten()\n",
    "\n",
    "    # Innovation or residual, should be a 2-element 1D array\n",
    "    y = z - H.dot(x_pred)\n",
    "    # System uncertainty, should be a 2x2 matrix\n",
    "    S = H.dot(P_pred).dot(H.T) + R\n",
    "    # Kalman gain, should be a 2x2 matrix\n",
    "    K = P_pred.dot(H.T).dot(np.linalg.inv(S))\n",
    "    # Updated state estimate, should be a 2-element 1D array\n",
    "    x_update = x_pred + K.dot(y)\n",
    "    I = np.eye(P_pred.shape[0])  # Identity matrix\n",
    "    # Updated estimate uncertainty, should be a 2x2 matrix\n",
    "    P_update = (I - K.dot(H)).dot(P_pred)\n",
    "\n",
    "    return x_update, P_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4fba50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positions(obj_centers, num_passes):\n",
    "    P = np.eye(2)\n",
    "    A = np.eye(2) * 0.9972\n",
    "    x = [312, 228]\n",
    "    H = np.eye(2)\n",
    "    Q = np.eye(2) * 0.01\n",
    "    R = np.eye(2) * 1\n",
    "    \n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    \n",
    "    positions = {}\n",
    "    positions[\"obj\"] = []\n",
    "\n",
    "    frames = []\n",
    "    ok, image = cap.read()\n",
    "    \n",
    "    forward = True\n",
    "    for i in range(num_passes):\n",
    "        count = 0\n",
    "        if (not forward):\n",
    "            x = frames[-1]\n",
    "            frames = frames[::-1]\n",
    "            A = np.eye(2) * 1.0028\n",
    "            forward = True\n",
    "        else:\n",
    "            if (i != 0):\n",
    "                x = frames[0]\n",
    "            forward= False\n",
    "            A = np.eye(2) * 0.9972\n",
    "            \n",
    "        while count < len(obj_centers):\n",
    "            if(count == 0 and i== 0):\n",
    "                count += 1\n",
    "                continue\n",
    "            else:\n",
    "                pos_x, pos_y = obj_centers[count]\n",
    "                count += 1\n",
    "                if pos_x != -1 and pos_y != -1:\n",
    "                    z = np.array([pos_x, pos_y])\n",
    "                    if count == 1 and i == 0:\n",
    "                        x = np.array([pos_x, pos_y])\n",
    "                        P = np.diag([1, 1])\n",
    "                    else:\n",
    "                        x_pred, P_pred = predict(x, P, A, Q)  # predict next frame\n",
    "                        x_update, P_update = update(x_pred, P_pred, z, H, R)\n",
    "                        x_update = x_update.tolist()\n",
    "                        frames.append([pos_x, pos_y])\n",
    "                        positions[\"obj\"] += [[pos_x, pos_y]]\n",
    "                        x, P = x_update, P_update\n",
    "                else:\n",
    "                    x, P = predict(x, P, A, Q)\n",
    "                    x = x.tolist()  # check the rounding issue\n",
    "                    frames.append([x[0], x[1]])\n",
    "                    positions[\"obj\"] += [[x[0], x[1]]]\n",
    "    \n",
    "               \n",
    "        if (not forward):\n",
    "            frames = frames[::-1]\n",
    "            \n",
    "                \n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "13473324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_target_object_center(video_file, obj_centers, forward_pass = True):\n",
    "    P = np.eye(2) \n",
    "    if(forward_pass):\n",
    "        A = np.eye(2) * 0.9972\n",
    "        x = [312, 228]\n",
    "    else:\n",
    "        A = np.eye(2) * 1.0028\n",
    "        x = [155.48221359647187, 95.25131111414534]\n",
    "    H = np.eye(2)\n",
    "    Q = np.eye(2) * 0.01\n",
    "    R = np.eye(2) * 1\n",
    "    count = 0\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    \n",
    "    \n",
    "    positions = {}\n",
    "    positions[\"obj\"] = []\n",
    "    \n",
    "    frames = []  \n",
    "    ok, image = cap.read()\n",
    "    vidwrite = cv.VideoWriter(\"part_1_demo_with_kalman.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "    \n",
    "    \n",
    "    while ok:\n",
    "        if(count == 0 and forward_pass):\n",
    "            count += 1\n",
    "            continue\n",
    "        elif count == 249 and forward_pass:\n",
    "            break\n",
    "        # print(count)\n",
    "        pos_x, pos_y = obj_centers[count]\n",
    "        count += 1\n",
    "        if pos_x != -1 and pos_y != -1:\n",
    "            z = np.array([pos_x, pos_y])\n",
    "            if count == 1:\n",
    "                x = np.array([pos_x, pos_y])\n",
    "                P = np.diag([1, 1])\n",
    "            else:\n",
    "\n",
    "                x_pred, P_pred = predict(x, P, A, Q) #predict next frame \n",
    "\n",
    "                x_update, P_update = update(x_pred, P_pred, z, H, R) #\n",
    "                \n",
    "                x_update = x_update.tolist()\n",
    "                \n",
    "                frames.append([pos_x, pos_y])\n",
    "                positions[\"obj\"] += [[pos_x, pos_y]]\n",
    "                # print(x_update)\n",
    "                image = cv.resize(image, (700, 500))\n",
    "                # print(x_update[0], x_update[1])\n",
    "                # if len(frames) > 1:\n",
    "                #     cv.polylines(image, [np.array(frames)], False, (0, 0, 255), thickness=1)\n",
    "\n",
    "                x, P = x_update, P_update\n",
    "        else:\n",
    "            # print(x)\n",
    "            x, P = predict(x, P, A, Q)\n",
    "            x = x.tolist() #check the rounding issue\n",
    "            frames.append([x[0], x[1]])\n",
    "            positions[\"obj\"] += [[x[0], x[1]]]\n",
    "\n",
    "            # cv.polylines(image, [np.array(frames)], False, (0, 0, 255), thickness=1)\n",
    "        image = cv.resize(image, (700, 500))\n",
    "        # image = cv.circle(image, (pos_x, pos_y), 1, (0, 0, 255), 2)\n",
    "\n",
    "        vidwrite.write(image)\n",
    "        ok, image = cap.read()\n",
    "    vidwrite.release()\n",
    "    if(forward_pass):\n",
    "       filename = 'filled_positions.json'\n",
    "    else:\n",
    "        filename = 'backwards_filled_positions.json'\n",
    "        frames = frames[::-1]\n",
    "        positions[\"obj\"] = positions[\"obj\"][::-1]\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(positions, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "80026fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "file_path = 'backwards_filled_positions.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    object_pos = json.load(file)\n",
    "    \n",
    "print(len(object_pos['obj']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "50fb5637",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     object_pos \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(file)\n\u001b[1;32m      6\u001b[0m \u001b[39m# draw_target_object_center(video_file, object_pos['obj'])\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m generate_positions(object_pos, \u001b[39m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[176], line 26\u001b[0m, in \u001b[0;36mgenerate_positions\u001b[0;34m(obj_centers, num_passes)\u001b[0m\n\u001b[1;32m     24\u001b[0m     forward \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     x \u001b[39m=\u001b[39m frames[\u001b[39m0\u001b[39m]\n\u001b[1;32m     27\u001b[0m     forward\u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     A \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39meye(\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m0.9972\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "file_path = 'part_1_object_tracking.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    object_pos = json.load(file)\n",
    "\n",
    "# draw_target_object_center(video_file, object_pos['obj'])\n",
    "generate_positions(object_pos, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1db00845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# back_pos = [[-1, -1]] + object_pos['obj']\n",
    "# draw_target_object_center(video_file, back_pos[::-1], False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bad71103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "[312, 228]\n",
      "[311, 228]\n",
      "[318, 205]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[307, 225]\n",
      "[306, 224]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[287, 207]\n",
      "[287, 206]\n",
      "[286, 205]\n",
      "[286, 203]\n",
      "[-1, -1]\n",
      "[285, 202]\n",
      "[284, 202]\n",
      "[-1, -1]\n",
      "[-1, -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[278, 198]\n",
      "[276, 197]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[275, 196]\n",
      "[-1, -1]\n",
      "[272, 194]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[262, 186]\n",
      "[261, 186]\n",
      "[260, 184]\n",
      "[260, 185]\n",
      "[259, 184]\n",
      "[258, 184]\n",
      "[257, 183]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[252, 176]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[232, 156]\n",
      "[232, 156]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[225, 148]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[224, 148]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[219, 141]\n",
      "[218, 141]\n",
      "[217, 141]\n",
      "[216, 139]\n",
      "[216, 139]\n",
      "[216, 139]\n",
      "[216, 139]\n",
      "[216, 138]\n",
      "[-1, -1]\n",
      "[213, 138]\n",
      "[212, 137]\n",
      "[213, 136]\n",
      "[211, 136]\n",
      "[212, 135]\n",
      "[211, 135]\n",
      "[210, 132]\n",
      "[211, 132]\n",
      "[-1, -1]\n",
      "[209, 132]\n",
      "[207, 132]\n",
      "[207, 131]\n",
      "[205, 131]\n",
      "[206, 131]\n",
      "[205, 130]\n",
      "[204, 130]\n",
      "[203, 130]\n",
      "[203, 130]\n",
      "[203, 129]\n",
      "[203, 128]\n",
      "[202, 128]\n",
      "[-1, -1]\n",
      "[199, 128]\n",
      "[199, 127]\n",
      "[198, 127]\n",
      "[198, 127]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[193, 121]\n",
      "[193, 122]\n",
      "[193, 120]\n",
      "[193, 120]\n",
      "[192, 120]\n",
      "[-1, -1]\n",
      "[190, 120]\n",
      "[191, 120]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[177, 109]\n",
      "[178, 108]\n",
      "[177, 108]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[171, 108]\n",
      "[-1, -1]\n",
      "[171, 107]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[170, 107]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[169, 102]\n",
      "[168, 103]\n",
      "[168, 103]\n",
      "[167, 102]\n",
      "[167, 102]\n",
      "[167, 101]\n",
      "[167, 101]\n",
      "[166, 100]\n",
      "[166, 101]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "Iteration 1\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[166, 101]\n",
      "[166, 100]\n",
      "[167, 101]\n",
      "[167, 101]\n",
      "[167, 102]\n",
      "[167, 102]\n",
      "[168, 103]\n",
      "[168, 103]\n",
      "[169, 102]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[170, 107]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[171, 107]\n",
      "[-1, -1]\n",
      "[171, 108]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[177, 108]\n",
      "[178, 108]\n",
      "[177, 109]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[191, 120]\n",
      "[190, 120]\n",
      "[-1, -1]\n",
      "[192, 120]\n",
      "[193, 120]\n",
      "[193, 120]\n",
      "[193, 122]\n",
      "[193, 121]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[198, 127]\n",
      "[198, 127]\n",
      "[199, 127]\n",
      "[199, 128]\n",
      "[-1, -1]\n",
      "[202, 128]\n",
      "[203, 128]\n",
      "[203, 129]\n",
      "[203, 130]\n",
      "[203, 130]\n",
      "[204, 130]\n",
      "[205, 130]\n",
      "[206, 131]\n",
      "[205, 131]\n",
      "[207, 131]\n",
      "[207, 132]\n",
      "[209, 132]\n",
      "[-1, -1]\n",
      "[211, 132]\n",
      "[210, 132]\n",
      "[211, 135]\n",
      "[212, 135]\n",
      "[211, 136]\n",
      "[213, 136]\n",
      "[212, 137]\n",
      "[213, 138]\n",
      "[-1, -1]\n",
      "[216, 138]\n",
      "[216, 139]\n",
      "[216, 139]\n",
      "[216, 139]\n",
      "[216, 139]\n",
      "[217, 141]\n",
      "[218, 141]\n",
      "[219, 141]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[224, 148]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[225, 148]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[232, 156]\n",
      "[232, 156]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[252, 176]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[257, 183]\n",
      "[258, 184]\n",
      "[259, 184]\n",
      "[260, 185]\n",
      "[260, 184]\n",
      "[261, 186]\n",
      "[262, 186]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[272, 194]\n",
      "[-1, -1]\n",
      "[275, 196]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[276, 197]\n",
      "[278, 198]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[284, 202]\n",
      "[285, 202]\n",
      "[-1, -1]\n",
      "[286, 203]\n",
      "[286, 205]\n",
      "[287, 206]\n",
      "[287, 207]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[306, 224]\n",
      "[307, 225]\n",
      "[-1, -1]\n",
      "[-1, -1]\n",
      "[318, 205]\n",
      "[311, 228]\n",
      "[312, 228]\n",
      "-1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     back_pos \u001b[39m=\u001b[39m object_pos[\u001b[39m'\u001b[39m\u001b[39mobj\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m object_pos[\u001b[39m'\u001b[39m\u001b[39mobj\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m:]\n\u001b[0;32m---> 13\u001b[0m     draw_target_object_center(video_file, back_pos[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], flag, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m     flag \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[172], line 31\u001b[0m, in \u001b[0;36mdraw_target_object_center\u001b[0;34m(video_file, obj_centers, forward_pass, second_loop)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(obj_centers[count])\n\u001b[0;32m---> 31\u001b[0m pos_x, pos_y \u001b[39m=\u001b[39m obj_centers[count]\n\u001b[1;32m     32\u001b[0m count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m pos_x \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m pos_y \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d28e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[312, 228]\n",
      "[312, 228]\n",
      "[312, 228]\n",
      "[314, 222]\n",
      "[314, 222]\n",
      "[314, 222]\n",
      "[313, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[312, 223]\n",
      "[308, 220]\n",
      "[305, 218]\n",
      "[302, 216]\n",
      "[300, 214]\n",
      "[300, 214]\n",
      "[298, 213]\n",
      "[296, 212]\n",
      "[296, 212]\n",
      "[296, 212]\n",
      "[296, 212]\n",
      "[296, 212]\n",
      "[296, 212]\n",
      "[296, 212]\n",
      "[294, 210]\n",
      "[292, 209]\n",
      "[292, 209]\n",
      "[292, 209]\n",
      "[290, 208]\n",
      "[290, 208]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[288, 207]\n",
      "[285, 205]\n",
      "[283, 203]\n",
      "[281, 201]\n",
      "[279, 199]\n",
      "[277, 198]\n",
      "[275, 197]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[273, 196]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[271, 194]\n",
      "[267, 190]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[264, 187]\n",
      "[260, 183]\n",
      "[260, 183]\n",
      "[260, 183]\n",
      "[257, 180]\n",
      "[257, 180]\n",
      "[257, 180]\n",
      "[257, 180]\n",
      "[257, 180]\n",
      "[257, 180]\n",
      "[257, 180]\n",
      "[257, 180]\n",
      "[253, 176]\n",
      "[250, 173]\n",
      "[247, 170]\n",
      "[244, 167]\n",
      "[241, 164]\n",
      "[239, 162]\n",
      "[237, 160]\n",
      "[235, 158]\n",
      "[235, 158]\n",
      "[233, 156]\n",
      "[231, 154]\n",
      "[229, 152]\n",
      "[227, 150]\n",
      "[226, 149]\n",
      "[225, 148]\n",
      "[224, 146]\n",
      "[223, 145]\n",
      "[223, 145]\n",
      "[222, 144]\n",
      "[221, 143]\n",
      "[220, 142]\n",
      "[219, 141]\n",
      "[218, 140]\n",
      "[217, 139]\n",
      "[216, 138]\n",
      "[215, 137]\n",
      "[214, 136]\n",
      "[213, 135]\n",
      "[212, 134]\n",
      "[211, 133]\n",
      "[211, 133]\n",
      "[210, 133]\n",
      "[209, 132]\n",
      "[208, 132]\n",
      "[207, 132]\n",
      "[207, 132]\n",
      "[207, 132]\n",
      "[207, 132]\n",
      "[207, 132]\n",
      "[207, 132]\n",
      "[207, 132]\n",
      "[207, 132]\n",
      "[207, 132]\n",
      "[207, 132]\n",
      "[206, 131]\n",
      "[205, 130]\n",
      "[204, 129]\n",
      "[203, 128]\n",
      "[202, 127]\n",
      "[202, 127]\n",
      "[201, 126]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[200, 125]\n",
      "[198, 123]\n",
      "[196, 122]\n",
      "[194, 121]\n",
      "[194, 121]\n",
      "[194, 121]\n",
      "[194, 121]\n",
      "[194, 121]\n",
      "[192, 120]\n",
      "[192, 120]\n",
      "[190, 119]\n",
      "[190, 119]\n",
      "[190, 119]\n",
      "[188, 118]\n",
      "[188, 118]\n",
      "[188, 118]\n",
      "[188, 118]\n",
      "[188, 118]\n",
      "[186, 116]\n",
      "[184, 115]\n",
      "[182, 114]\n",
      "[181, 113]\n",
      "[180, 112]\n",
      "[179, 111]\n",
      "[178, 110]\n",
      "[177, 109]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n",
      "[176, 108]\n"
     ]
    }
   ],
   "source": [
    "video_file = \"commonwealth.mp4\"\n",
    "draw_target_object_center(video_file, object_pos['obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "eca5487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_path(video_file, obj_centers):\n",
    "    obj_centers = [[int(round(x[0])), int(round(x[1]))] for x in obj_centers]\n",
    "    count = 0\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    ok, image = cap.read()\n",
    "    vidwrite = cv.VideoWriter(\n",
    "        \"part_1_demo_with_kalman.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700, 500))\n",
    "\n",
    "    while ok:\n",
    "        if(count == 0):\n",
    "            count += 1\n",
    "            continue\n",
    "        elif count == 248:\n",
    "            break\n",
    "        # print(count)\n",
    "        pos_x, pos_y = obj_centers[count]\n",
    "        count += 1\n",
    "        image = cv.resize(image, (700, 500))\n",
    "        # print([np.array(obj_centers[:count+1])])\n",
    "        cv.polylines(image, [np.array(obj_centers[:count+1])],\n",
    "                     False, (0, 0, 255), thickness=2)\n",
    "        image = cv.circle(image, (pos_x, pos_y), 1, (0, 0, 255), 2)        \n",
    "        vidwrite.write(image)\n",
    "        ok, image = cap.read()\n",
    "    vidwrite.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7ceaa61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "file_path = 'backwards_filled_positions.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    object_pos = json.load(file)\n",
    "    \n",
    "\n",
    "create_video_path(video_file, object_pos['obj'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dae2bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n"
     ]
    }
   ],
   "source": [
    "print(len(object_pos[\"obj\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9db6b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# part 2:\n",
    "\n",
    "def draw_object(object_dict,image,color = (0, 255, 0), thickness = 2,c_color= \\\n",
    "                (255, 0, 0)):\n",
    "  # draw box\n",
    "  x = object_dict['x_min']\n",
    "  y = object_dict['y_min']\n",
    "  width = object_dict['width']\n",
    "  height = object_dict['height']\n",
    "  image = cv.rectangle(image, (x, y), (x + width, y + height), color, thickness)\n",
    "  return image\n",
    "\n",
    "def draw_objects_in_video(video_file,frame_dict):\n",
    "  count = 0\n",
    "  cap = cv.VideoCapture(video_file)\n",
    "  frames = []\n",
    "  ok, image = cap.read()\n",
    "  vidwrite = cv.VideoWriter(\"part_2_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "  while ok:\n",
    "    ######!!!!#######\n",
    "    image = cv.resize(image, (700, 500)) # make sure your video is resize to this size, otherwise the coords in the data file won't work !!!\n",
    "    ######!!!!#######\n",
    "    obj_list = frame_dict[str(count)]\n",
    "    for obj in obj_list:\n",
    "      image = draw_object(obj,image)\n",
    "    vidwrite.write(image)\n",
    "    count+=1\n",
    "    ok, image = cap.read()\n",
    "  vidwrite.release()\n",
    "\n",
    "frame_dict = load_obj_each_frame(\"frame_dict.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_objects_in_video(video_file,frame_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cc378a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiObjKalmanFilter:\n",
    "    def __init__(self, ):\n",
    "        self.towards_A_matrix = np.eye(2) * 1.0028\n",
    "        self.away_A_matrix = np.eye(2) * 0.9972\n",
    "        self.stationary_A_matrix = np.eye(2)\n",
    "        self.H = np.eye(2)\n",
    "        self.Q = np.eye(2) * 0.01\n",
    "        self.R = np.eye(2) * 1\n",
    "        self.A = self.stationary_A_matrix  # Default A matrix\n",
    "        self.x = np.zeros(2)  # Initial state estimate\n",
    "        self.P = np.eye(2)  # Initial covariance estimate\n",
    "        self.x_last = self.x\n",
    "\n",
    "    def set_motion_status(self):\n",
    "        result = np.around(self.x) - self.x_last\n",
    "        if np.all(result > 0):\n",
    "            self.A = self.towards_A_matrix\n",
    "        elif np.all(result < 0):\n",
    "            self.A = self.away_A_matrix\n",
    "        elif np.all(result = 0):\n",
    "            self.A = self.stationary_A_matrix\n",
    "        else:\n",
    "            raise ValueError(\"Invalid motion status\")\n",
    "\n",
    "    def update(self, z):\n",
    "        self.x_last = z\n",
    "        y = z - self.H.dot(self.x)\n",
    "        S = self.H.dot(self.P).dot(self.H.T) + self.R\n",
    "        K = self.P.dot(self.H.T).dot(np.linalg.inv(S))\n",
    "        self.x = self.x + K.dot(y)\n",
    "        I = np.eye(self.P.shape[0])\n",
    "        self.P = (I - K.dot(self.H)).dot(self.P)\n",
    "        return self.x, self.P\n",
    "\n",
    "    def predict(self):\n",
    "        self.x = self.A.dot(self.x)\n",
    "        self.P = self.A.dot(self.P).dot(self.A.T) + self.Q\n",
    "        return self.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "889a95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update average width/height of a detected object\n",
    "\n",
    "def update_known_object_characteristics(id, object):\n",
    "    if id not in detected_obj_avg_size:\n",
    "        # If not, initialize the record for this object ID\n",
    "        detected_obj_avg_size[id] = {\n",
    "            'num_updates': 1,\n",
    "            'total_height': object['height'],\n",
    "            'total_width': object['width']\n",
    "        }\n",
    "    else:\n",
    "        detected_obj_avg_size[id]['num_updates'] += 1\n",
    "        detected_obj_avg_size[id]['total_height'] += object['height']\n",
    "        detected_obj_avg_size[id]['total_width'] += object['width']\n",
    "\n",
    "    detected_obj_avg_size[id]['avg_height'] = detected_obj_avg_size[id]['total_height'] / detected_obj_avg_size[id]['num_updates']\n",
    "    detected_obj_avg_size[id]['avg_width'] = detected_obj_avg_size[id]['total_width'] / detected_obj_avg_size[id]['num_updates']\n",
    "\n",
    "def get_similar_sized_object(obj):\n",
    "    min_diff = float('inf') \n",
    "    similar_obj_id = None\n",
    "    \n",
    "    for detected_obj in detected_obj_avg_size:\n",
    "        height_diff = abs(detected_obj['avg_height'] - obj['height'])\n",
    "        width_diff = abs(detected_obj['avg_width'] - obj['width'])\n",
    "        combined_diff = height_diff + width_diff  \n",
    "        \n",
    "        if combined_diff < min_diff:\n",
    "            min_diff = combined_diff\n",
    "            similar_obj_id = detected_obj['id']\n",
    "    \n",
    "    return similar_obj_id\n",
    "\n",
    "\n",
    "def are_coordinates_close(coord1, coord2, margin):\n",
    "   \n",
    "    distance = np.linalg.norm(np.array(coord1) - np.array(coord2))\n",
    "\n",
    "    return distance <= margin\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "47c27df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization step - give every object a unique ID \n",
    "file_path = 'part_2_frame_dict.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    obj_positions = json.load(file)\n",
    "\n",
    "\n",
    "#set the default ID to -1\n",
    "for frame in obj_positions.values():\n",
    "    for obj in frame:\n",
    "        obj['id'] = -1\n",
    "\n",
    "#keeps track of the size of previously ID'd objects, used to compare with the size of unkown objects to help\n",
    "#with identification\n",
    "# detected_obj_avg_size = {}\n",
    "\n",
    "\n",
    "#known objects\n",
    "prev_positions = obj_positions[\"0\"]\n",
    "\n",
    "#measurements\n",
    "curr_positions = obj_positions[\"1\"]\n",
    "\n",
    "#ID Numtracker:\n",
    "newest_id = 0\n",
    "\n",
    "pixel_threshold = 15\n",
    "\n",
    "\n",
    "for i in range(len(prev_positions)):\n",
    "    prev_positions[i]['id'] = i+1\n",
    "    newest_id += 1;\n",
    "\n",
    "detected_obj_tracks = {}\n",
    "detected_obj_kalmans = {}\n",
    "\n",
    "\n",
    "#initialize kalman filters for all existing objects\n",
    "for object in prev_positions:\n",
    "    detected_obj_kalmans[object['id']] = MultiObjKalmanFilter()\n",
    "    detected_obj_kalmans[object['id']].x = np.array((object[\"x_min\"], object[\"y_min\"]))\n",
    "    detected_obj_tracks[object['id']] = object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3f9f146a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "all() got an unexpected keyword argument 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 42\u001b[0m\n\u001b[1;32m     37\u001b[0m     detected_obj_kalmans[\u001b[39mobject\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m     38\u001b[0m         np\u001b[39m.\u001b[39marray([new_det[\u001b[39m\"\u001b[39m\u001b[39mx_min\u001b[39m\u001b[39m\"\u001b[39m], new_det[\u001b[39m\"\u001b[39m\u001b[39my_min\u001b[39m\u001b[39m\"\u001b[39m]]))\n\u001b[1;32m     40\u001b[0m     \u001b[39m# if match, that object now has a set model for the future\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     detected_obj_kalmans[\u001b[39mobject\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 42\u001b[0m                          ]\u001b[39m.\u001b[39mset_motion_status()\n\u001b[1;32m     43\u001b[0m     matched \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[135], line 20\u001b[0m, in \u001b[0;36mMultiObjKalmanFilter.set_motion_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39mall(result \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m     19\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maway_A_matrix\n\u001b[0;32m---> 20\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39mall(result \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m     21\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstationary_A_matrix\n\u001b[1;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:198\u001b[0m, in \u001b[0;36mall\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: all() got an unexpected keyword argument 'result'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for frame in list(obj_positions.keys())[1:]:\n",
    "    curr_positions = obj_positions[frame]\n",
    "    \n",
    "    #loop handling old objects: assigning to new detections, or ruling them out as having left the frame\n",
    "    for object in prev_positions:\n",
    "        matched = False\n",
    "        obj_estimates = [] #array containing the 3 possible estimated locations of the obj\n",
    "        \n",
    "        #make an estimation assuming motion towards the camera\n",
    "        detected_obj_kalmans[object['id']].set_motion_status()\n",
    "        towards_estimation = detected_obj_kalmans[object['id']].predict()\n",
    "        obj_estimates.append(towards_estimation)\n",
    "        \n",
    "        # #make an estimation assuming motion away from the camera\n",
    "        # detected_obj_kalmans[object['id']].set_motion_status(\"away\")\n",
    "        # away_estimation = detected_obj_kalmans[object['id']].predict()\n",
    "        # obj_estimates.append(away_estimation)\n",
    "        \n",
    "        # #make an estimation assuming motion stationary to the camera\n",
    "        # detected_obj_kalmans[object['id']].set_motion_status(\"stationary\")\n",
    "        # stationairy_estimation = detected_obj_kalmans[object['id']].predict()\n",
    "        # obj_estimates.append(stationairy_estimation)\n",
    "        \n",
    "        for new_det in curr_positions: #for every newly detected obj\n",
    "            if matched:\n",
    "                break\n",
    "            for i in range(len(obj_estimates)): #for all 3 estimations\n",
    "                # check if model finds a match\n",
    "                if are_coordinates_close(obj_estimates[i].tolist(), [new_det[\"x_min\"], new_det[\"y_min\"]], pixel_threshold):\n",
    "            \n",
    "                    \n",
    "                    new_det['id'] = object['id'] #link the new detection to an existing object\n",
    "                    \n",
    "                    #update the kalman filter instance's estimation with the new measurment, now confirmed to be for that object\n",
    "                    detected_obj_kalmans[object['id']].update(\n",
    "                        np.array([new_det[\"x_min\"], new_det[\"y_min\"]]))\n",
    "                    \n",
    "                    # if match, that object now has a set model for the future\n",
    "                    detected_obj_kalmans[object['id']\n",
    "                                         ].set_motion_status()\n",
    "                    matched = True\n",
    "                else:\n",
    "                    continue \n",
    "            \n",
    "            \n",
    "            \n",
    "    #loop handling new objects that have not found a match from previous frame (could either be new objects or objects that already exist but were\n",
    "    # not in the previous frame for whatever reason)\n",
    "    for new_detection in curr_positions:\n",
    "        if new_detection['id'] == -1: #if obj not classified TODO: change the default ID to -1 to avoid errors\n",
    "            matched = False\n",
    "            for old_obj in detected_obj_tracks.values():\n",
    "                if are_coordinates_close(np.array([new_detection[\"x_min\"], new_detection[\"y_min\"]]), np.array([old_obj[\"x_min\"], old_obj[\"y_min\"]]), pixel_threshold):\n",
    "                    #the \"new\" object was actually an old object that we lost track of in the last frame\n",
    "                    new_detection['id'] = old_obj['id'] #update it's ID and kalman filters accordingly \n",
    "                    detected_obj_kalmans[object['id']].update(\n",
    "                        np.array([new_detection[\"x_min\"], new_detection[\"y_min\"]]))\n",
    "                    matched = True\n",
    "            \n",
    "            if (not matched): #the new object was not detected in the last frame or any previous frames, create a new object ID for it \n",
    "                newest_id += 1  # create a new ID for the new obj and assign\n",
    "                new_detection['id'] = newest_id\n",
    "                #create its kalman filter instance and initialize it\n",
    "                detected_obj_kalmans[new_detection['id']] = MultiObjKalmanFilter()\n",
    "                detected_obj_kalmans[new_detection['id']].x = np.array(\n",
    "                    [new_detection[\"x_min\"], new_detection[\"y_min\"]])\n",
    "\n",
    "\n",
    "    for new_detection in curr_positions:\n",
    "    #update the object database withe the new coordinates of all currently tracked objects\n",
    "        detected_obj_tracks[new_detection['id']\n",
    "                            ] = new_detection\n",
    "    \n",
    "    \n",
    "    #update all filters anyways (incase we lost track of an object that will re-appear later)\n",
    "    for object in detected_obj_kalmans.values():\n",
    "        object.predict()\n",
    "        \n",
    "        \n",
    "    #the curr_positions dictionairy now contains identified objects\n",
    "    obj_positions[frame] = curr_positions\n",
    "    prev_positions = curr_positions\n",
    "    \n",
    "\n",
    "file_path = \"obj_detections_test.json\"\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(obj_positions, json_file)\n",
    "\n",
    "file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86940b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given input array:\n",
      "[[15 15  0]\n",
      " [ 0  0 10]\n",
      " [ 5  5  0]]\n",
      "\n",
      "m2 array (max num of zeroes from horizontal vs vertical) (- for horizontal and + for vertical):\n",
      "[[ 1  1  2]\n",
      " [-2 -2  2]\n",
      " [ 1  1  2]]\n",
      "\n",
      "Lines array:\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# for each new frame\n",
    "\n",
    "    #for each old object\n",
    "        #estimate 3 possible locations\n",
    "            #assuming:\n",
    "                #stationairy model\n",
    "                #towards model\n",
    "                #away model\n",
    "            \n",
    "            #get 3 coord positions\n",
    "            \n",
    "        #for each new detection:\n",
    "            #check for each prediction to see if match \n",
    "                #if match: \n",
    "                    #go to frame dict [frame#]: find box with matching coord, set ID \n",
    "                    # update estimations for that object \n",
    "                #else no match:\n",
    "                    #assume object has left frame \n",
    "\n",
    "    #for each new detection:\n",
    "        #if detection not given an ID\n",
    "        #give new ID \n",
    "        \n",
    "    #set old_detections = new_detections\n",
    "    \n",
    "    \n",
    "\n",
    "#loop to next frame\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e9565f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import json\n",
    "\n",
    "\n",
    "def load_obj_each_frame(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def draw_object(object_dict, image, color=(0, 255, 0), thickness=2, c_color=(255, 0, 0)):\n",
    "  # draw box\n",
    "  x = object_dict['x_min']\n",
    "  y = object_dict['y_min']\n",
    "  width = object_dict['width']\n",
    "  height = object_dict['height']\n",
    "  id = object_dict['id']\n",
    "  image = cv.rectangle(\n",
    "      image, (x, y), (x + width, y + height), color, thickness)\n",
    "  cv.putText(image, str(id), (x, y - 10),\n",
    "             cv.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "  return image\n",
    "\n",
    "def draw_objects_in_video(video_file, frame_dict):\n",
    "  count = 0\n",
    "  cap = cv.VideoCapture(video_file)\n",
    "  frames = []\n",
    "  ok, image = cap.read()\n",
    "  vidwrite = cv.VideoWriter(\n",
    "      \"part_2_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700, 500))\n",
    "  while ok:\n",
    "    ######!!!!#######\n",
    "    # make sure your video is resize to this size, otherwise the coords in the data file won't work !!!\n",
    "    image = cv.resize(image, (700, 500))\n",
    "    ######!!!!#######\n",
    "    obj_list = frame_dict[str(count)]\n",
    "    for obj in obj_list:\n",
    "      image = draw_object(obj, image)\n",
    "    vidwrite.write(image)\n",
    "    count += 1\n",
    "    ok, image = cap.read()\n",
    "  vidwrite.release()\n",
    "\n",
    "\n",
    "# Assuming the JSON file is named \"frame_dict.json\" and the video file is named \"commonwealth.mp4\"\n",
    "frame_dict = load_obj_each_frame(\"obj_detections_test.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_objects_in_video(video_file, frame_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
